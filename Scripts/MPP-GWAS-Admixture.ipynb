{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ae8a86b",
   "metadata": {},
   "source": [
    "# Load all libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b74f5fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import torch\n",
    "import random\n",
    "import warnings\n",
    "import subprocess\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import concurrent.futures\n",
    "from functools import partial\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from statsmodels.formula.api import ols\n",
    "from pandas_plink import read_plink1_bin, read_plink"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3929e1",
   "metadata": {},
   "source": [
    "# Helper Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8dda8005",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(metric, pred_betas_df):\n",
    "    \n",
    "    #Pred Betas\n",
    "    pred_betas = np.array(pred_betas_df['BETA'], dtype=float)\n",
    "    \n",
    "    inPATH = '/Users/ritwizkamal/BIRDS_server/AA_FinalGithub/example_data/'\n",
    "    Beta_true = pd.read_csv(inPATH+'beta_tar_sas_truebetas.txt', delimiter=' ',\\\n",
    "                            header=None, names=['BETA'])\n",
    "    Beta_true = np.array(Beta_true['BETA'], dtype=float)\n",
    "    \n",
    "    #Train R2\n",
    "    G_sas_train = read_plink1_bin(inPATH+'target_training_geno.bed',\\\n",
    "                                  inPATH+'target_training_geno.bim',\\\n",
    "                                  inPATH+'target_training_geno.fam',\\\n",
    "                                  verbose = False)\n",
    "    X_sas_train = G_sas_train.values\n",
    "    X_sas_train = np.where(X_sas_train == 2, 0, np.where(X_sas_train == 0, 2, X_sas_train))\n",
    "    X_sas_train = np.array(X_sas_train, dtype=float)\n",
    "\n",
    "    Y_train_true = pd.read_csv(inPATH+'pheno_tar_sas_train_truepheno.txt', delimiter=' ',\\\n",
    "                               header=None, names = ['Pheno'])\n",
    "    Y_train_true = np.array(Y_train_true['Pheno'], dtype=float)\n",
    "    \n",
    "    pred_y_train = np.matmul(X_sas_train, pred_betas)\n",
    "    r2_fit_data_train = pd.DataFrame({'Y_true':Y_train_true, 'Y_pred':pred_y_train})\n",
    "    r2_fit_model_train = ols('Y_true ~ Y_pred', data = r2_fit_data_train).fit()\n",
    "    r2_train = r2_fit_model_train.rsquared\n",
    "    \n",
    "    Y_train_bestpossible = np.matmul(X_sas_train, Beta_true)\n",
    "    numerator = sp.stats.pearsonr(Y_train_true, pred_y_train)[0]\n",
    "    denominator = sp.stats.pearsonr(Y_train_true, Y_train_bestpossible)[0]\n",
    "    cr_train = numerator/denominator\n",
    "    \n",
    "    #Val R2\n",
    "    G_sas_val = read_plink1_bin(inPATH+'target_validation_geno.bed',\\\n",
    "                                inPATH+'target_validation_geno.bim',\\\n",
    "                                inPATH+'target_validation_geno.fam',\\\n",
    "                                verbose = False)\n",
    "    X_sas_val = G_sas_val.values\n",
    "    X_sas_val = np.where(X_sas_val == 2, 0, np.where(X_sas_val == 0, 2, X_sas_val))\n",
    "    X_sas_val = np.array(X_sas_val, dtype=float)\n",
    "\n",
    "    Y_val_true = pd.read_csv(inPATH+'pheno_tar_sas_val_truepheno.txt', delimiter=' ',\\\n",
    "                             header=None, names=['Pheno'])\n",
    "    Y_val_true = np.array(Y_val_true['Pheno'], dtype=float)\n",
    "    \n",
    "    pred_y_val = np.matmul(X_sas_val, pred_betas)\n",
    "    r2_fit_data_val = pd.DataFrame({'Y_true':Y_val_true, 'Y_pred':pred_y_val})\n",
    "    r2_fit_model_val = ols('Y_true ~ Y_pred', data = r2_fit_data_val).fit()\n",
    "    r2_val = r2_fit_model_val.rsquared\n",
    "    \n",
    "    Y_val_bestpossible = np.matmul(X_sas_val, Beta_true)\n",
    "    numerator = sp.stats.pearsonr(Y_val_true, pred_y_val)[0]\n",
    "    denominator = sp.stats.pearsonr(Y_val_true, Y_val_bestpossible)[0]\n",
    "    cr_val = numerator/denominator\n",
    "    \n",
    "    #Test R2\n",
    "    G_sas_test = read_plink1_bin(inPATH+'target_testing_geno.bed',\\\n",
    "                                 inPATH+'target_testing_geno.bim',\\\n",
    "                                 inPATH+'target_testing_geno.fam',\\\n",
    "                                 verbose = False)\n",
    "    X_sas_test = G_sas_test.values\n",
    "    X_sas_test = np.where(X_sas_test == 2, 0, np.where(X_sas_test == 0, 2, X_sas_test))\n",
    "    X_sas_test = np.array(X_sas_test, dtype=float)\n",
    "\n",
    "    Y_test_true = pd.read_csv(inPATH+'pheno_tar_sas_test_truepheno.txt', delimiter=' ',\\\n",
    "                              header=None, names=['Pheno'])\n",
    "    Y_test_true = np.asarray(Y_test_true['Pheno'], dtype=float)\n",
    "    \n",
    "    pred_y_test = np.matmul(X_sas_test, pred_betas)\n",
    "    r2_fit_data_test = pd.DataFrame({'Y_true':Y_test_true, 'Y_pred':pred_y_test})\n",
    "    r2_fit_model_test = ols('Y_true ~ Y_pred', data = r2_fit_data_test).fit()\n",
    "    r2_test = r2_fit_model_test.rsquared\n",
    "    \n",
    "    Y_test_bestpossible = np.matmul(X_sas_test, Beta_true)\n",
    "    numerator = sp.stats.pearsonr(Y_test_true, pred_y_test)[0]\n",
    "    denominator = sp.stats.pearsonr(Y_test_true, Y_test_bestpossible)[0]\n",
    "    cr_test = numerator/denominator\n",
    "    \n",
    "    if metric == 'R2':\n",
    "        out = (r2_train, r2_val, r2_test)\n",
    "    elif metric == 'CR':\n",
    "        out = (cr_train, cr_val, cr_test)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c4c7a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def doMPP(X_tar, Y_train_true, tar_snps, aux_betas, L1_penalty):\n",
    "    \n",
    "    #Initialize Beta_hats\n",
    "    Beta_hat_init = np.random.normal(0, 0.00000000001, len(tar_snps))\n",
    "    \n",
    "    X_tensor = torch.from_numpy(X_tar)\n",
    "    XtX = torch.matmul(X_tensor.T, X_tensor)\n",
    "    XtX_np = XtX.numpy()\n",
    "\n",
    "    y_tensor = torch.from_numpy(Y_train_true)\n",
    "    Xty = torch.matmul(X_tensor.T, y_tensor)\n",
    "    Xty_np = Xty.numpy()\n",
    "\n",
    "    mu = 0.1\n",
    "    L1_penalty = L1_penalty\n",
    "\n",
    "    def func(Bs, L1_penalty):\n",
    "        t1 = torch.matmul(X_tensor, torch.from_numpy(Bs)).numpy()\n",
    "        temp = Bs - aux_betas\n",
    "        nesterov = mu*np.log((0.5*np.exp(-temp/mu))+(0.5*np.exp(temp/mu)))\n",
    "        term2 = L1_penalty*sum(nesterov)\n",
    "        val = sum((Y_train_true - t1)**2) + term2\n",
    "        return val\n",
    "\n",
    "    def jacfunc(Bs, L1_penalty):\n",
    "        term1 = 2*torch.matmul(XtX, torch.from_numpy(Bs)).numpy()\n",
    "        term2 = 2*Xty_np\n",
    "        temp = Bs - aux_betas\n",
    "        nesterov = np.divide((-np.exp(-temp/mu) + np.exp(temp/mu)),(np.exp(-temp/mu) + np.exp(temp/mu)))\n",
    "        term3 = L1_penalty*nesterov\n",
    "        return term1-term2+term3\n",
    "\n",
    "    ans = sp.optimize.minimize(func, jac=jacfunc, x0=Beta_hat_init, args=(L1_penalty),\\\n",
    "                               method='L-BFGS-B', options={'maxfun':10})\n",
    "    \n",
    "    final_snps = tar_snps\n",
    "    final_betas = ans.x\n",
    "    final_chr = tar_chroms\n",
    "    final_pos = tar_pos\n",
    "    final_a1 = tar_a1\n",
    "    final_results_df = pd.DataFrame({'CHR':final_chr, 'SNP':final_snps, 'POS':final_pos,\\\n",
    "                                     'A1':final_a1, 'BETA':final_betas,})\n",
    "    \n",
    "    return final_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bbcb69",
   "metadata": {},
   "source": [
    "# Load and Pre-Process Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77ced004",
   "metadata": {},
   "outputs": [],
   "source": [
    "inPATH = '/Users/ritwizkamal/BIRDS_server/AA_FinalGithub/example_data/'\n",
    "\n",
    "#AUX Summary Statistics\n",
    "ss_df_aux1 = pd.read_csv(inPATH+'aux_eur_sumstat.txt', delimiter=' ', header=None,\\\n",
    "                         names = ['CHR','SNP','GENETIC.DIST','BP','A1','A2','BETA','SE','T','P','N'])\n",
    "ss_df_aux2 = pd.read_csv(inPATH+'aux_eas_sumstat.txt', delimiter=' ', header=None,\\\n",
    "                         names = ['CHR','SNP','GENETIC.DIST','BP','A1','A2','BETA','SE','T','P','N'])\n",
    "ss_df_aux3 = pd.read_csv(inPATH+'aux_amr_sumstat.txt', delimiter=' ', header=None,\\\n",
    "                         names = ['CHR','SNP','GENETIC.DIST','BP','A1','A2','BETA','SE','T','P','N'])\n",
    "ss_df_aux4 = pd.read_csv(inPATH+'aux_afr_sumstat.txt', delimiter=' ', header=None,\\\n",
    "                         names = ['CHR','SNP','GENETIC.DIST','BP','A1','A2','BETA','SE','T','P','N'])\n",
    "\n",
    "#TAR Summary Statistics\n",
    "ss_df_tar = pd.read_csv(inPATH+'target_sas_sumstat.txt', delimiter=' ', header=None,\\\n",
    "                        names = ['CHR','SNP','GENETIC.DIST','BP','A1','A2','BETA','SE','T','P','N'])\n",
    "\n",
    "#True X\n",
    "G_sas  = read_plink1_bin(inPATH+'target_training_geno.bed',\\\n",
    "                         inPATH+'target_training_geno.bim',\\\n",
    "                         inPATH+'target_training_geno.fam',\\\n",
    "                         verbose = False)\n",
    "X_sas = G_sas.values\n",
    "X_sas = np.where(X_sas == 2, 0, np.where(X_sas == 0, 2, X_sas))\n",
    "X_sas = np.array(X_sas, dtype=float)\n",
    "all_snps_sas_ld_full = G_sas.snp.values\n",
    "\n",
    "common_snps = list(set(ss_df_aux1['SNP']) & set(ss_df_aux2['SNP']) &\\\n",
    "                   set(ss_df_aux3['SNP']) & set(ss_df_aux4['SNP']) &\\\n",
    "                   set(ss_df_tar['SNP']) & set(all_snps_sas_ld_full))\n",
    "\n",
    "#Preprocess Target and Auxiliary Summ. Stats. File\n",
    "ss_df_tar = ss_df_tar[ss_df_tar['SNP'].isin(common_snps)]\n",
    "ss_df_aux1 = ss_df_aux1[ss_df_aux1['SNP'].isin(common_snps)]\n",
    "ss_df_aux2 = ss_df_aux2[ss_df_aux2['SNP'].isin(common_snps)]\n",
    "ss_df_aux3 = ss_df_aux3[ss_df_aux3['SNP'].isin(common_snps)]\n",
    "ss_df_aux4 = ss_df_aux4[ss_df_aux4['SNP'].isin(common_snps)]\n",
    "\n",
    "ss_df_tar = ss_df_tar.reset_index(drop=True)\n",
    "ss_df_aux1 = ss_df_aux1.reset_index(drop=True)\n",
    "ss_df_aux2 = ss_df_aux2.reset_index(drop=True)\n",
    "ss_df_aux3 = ss_df_aux3.reset_index(drop=True)\n",
    "ss_df_aux4 = ss_df_aux4.reset_index(drop=True)\n",
    "\n",
    "N_tar = int(ss_df_tar['N'][0])\n",
    "N_aux1 = int(ss_df_aux1['N'][0])\n",
    "N_aux2 = int(ss_df_aux2['N'][0])\n",
    "N_aux3 = int(ss_df_aux3['N'][0])\n",
    "N_aux4 = int(ss_df_aux4['N'][0])\n",
    "\n",
    "tar_snps = list(ss_df_tar['SNP'])\n",
    "tar_a1 = list(ss_df_tar['A1'])\n",
    "tar_pvals = np.asarray(list(ss_df_tar['P']), dtype='float')\n",
    "tar_betas = np.asarray(list(ss_df_tar['BETA']), dtype='float')\n",
    "tar_chroms = list(ss_df_tar['CHR'])\n",
    "tar_pos = np.asarray(list(ss_df_tar['BP']), dtype='float')\n",
    "tar_corr = np.asarray(list(ss_df_tar['BETA']), dtype='float')*N_tar\n",
    "\n",
    "aux1_snps = list(ss_df_aux1['SNP'])\n",
    "aux1_betas = np.asarray(list(ss_df_aux1['BETA']), dtype='float')\n",
    "\n",
    "aux2_snps = list(ss_df_aux2['SNP'])\n",
    "aux2_betas = np.asarray(list(ss_df_aux2['BETA']), dtype='float')\n",
    "\n",
    "aux3_snps = list(ss_df_aux3['SNP'])\n",
    "aux3_betas = np.asarray(list(ss_df_aux3['BETA']), dtype='float')\n",
    "\n",
    "aux4_snps = list(ss_df_aux4['SNP'])\n",
    "aux4_betas = np.asarray(list(ss_df_aux4['BETA']), dtype='float')\n",
    "\n",
    "#Preprocess Target Ref. file\n",
    "temp_set = set(tar_snps)\n",
    "temp_indices_tar = [i for i, e in enumerate(all_snps_sas_ld_full) if e in temp_set]\n",
    "all_snps_sas_ld_full = [i for i in all_snps_sas_ld_full if i in common_snps]\n",
    "X_tar = X_sas[:, temp_indices_tar]\n",
    "\n",
    "#True Y\n",
    "Y_train_true = pd.read_csv(inPATH+'pheno_tar_sas_train_truepheno.txt', delimiter=' ',\\\n",
    "                           header=None, names=['Pheno'])\n",
    "Y_train_true = np.array(Y_train_true['Pheno'], dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99ca951",
   "metadata": {},
   "source": [
    "# Assign Weightage to each auxiliary population:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcf58719",
   "metadata": {},
   "outputs": [],
   "source": [
    "pops_tuple = 'EurEasAmrAfr'\n",
    "\n",
    "admixture_file = pd.read_csv(inPATH+'admixEurEasAmrAfr.4.Q', delimiter=\" \", header=None)\n",
    "\n",
    "admixture_file = admixture_file.iloc[8000:(8000+N_tar),:].reset_index(drop=True)\n",
    "\n",
    "aux_betas = np.zeros((len(common_snps),))\n",
    "intermediate_betas = []\n",
    "\n",
    "for i in range(admixture_file.shape[0]):\n",
    "    temp = (aux1_betas*admixture_file.iloc[i,0]) + (aux2_betas*admixture_file.iloc[i,1]) +\\\n",
    "    (aux3_betas*admixture_file.iloc[i,2]) + (aux4_betas*admixture_file.iloc[i,3])\n",
    "    intermediate_betas.append(temp)\n",
    "\n",
    "for i in range(intermediate_betas[0].shape[0]):\n",
    "    temp_snp_betas = [k[i] for k in intermediate_betas]\n",
    "    aux_betas[i] = np.median(temp_snp_betas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45630924",
   "metadata": {},
   "source": [
    "# Run MultiPopPred:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7088499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time: 2025-07-08 14:37:55.945716\n",
      "End time: 2025-07-08 14:37:56.673642\n"
     ]
    }
   ],
   "source": [
    "print('Start time: '+str(datetime.now()))\n",
    "result_df = doMPP(X_tar, Y_train_true, tar_snps, aux_betas, 7.5)\n",
    "print('End time: '+str(datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e090ddb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation Ratio Train: 1.0650038986810137\n",
      "Correlation Ratio Val: 0.7135191566349091\n",
      "Correlation Ratio Test: 0.6844775820834249\n"
     ]
    }
   ],
   "source": [
    "out = evaluate('CR', result_df)\n",
    "print('Correlation Ratio Train: '+str(out[0]))\n",
    "print('Correlation Ratio Val: '+str(out[1]))\n",
    "print('Correlation Ratio Test: '+str(out[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f662308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Train: 0.7622618884105195\n",
      "R2 Val: 0.35993864410059795\n",
      "R2 Test: 0.31948923331287127\n"
     ]
    }
   ],
   "source": [
    "out = evaluate('R2', result_df)\n",
    "print('R2 Train: '+str(out[0]))\n",
    "print('R2 Val: '+str(out[1]))\n",
    "print('R2 Test: '+str(out[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0a9058",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7d0642",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b02f0df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4614e850",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
